These sound examples accompany our paper: Sturm, Santos, Ben-Tal and Korshunova, “Music transcription modelling and composition using deep learning”, in Proc. [1st Conf. Computer Simulation of Musical Creativity](https://csmc2016.wordpress.com), Huddersfield, UK, July 2016.

Here is a description of the contents.

Directories:
- successes: synthesis of generated transcriptions we find plausible and consistent of the stylistic conventions in the training data

- nearmisses: synthesis of generated transcriptions we find plausible, but at times inconsistent with the stylistic conventions in the training data (for instance, accidentals, rhythm, structure)

- totalmisses: synthesis of generated transcriptions we find implausible

- compositions: synthesis of my compositions created using the systems
 * [“The March of Deep Learning”](https://soundcloud.com/sturmen-1/the-march-of-deep-learning) is discussed in the paper
 * “Eight Short Outputs” is created from my orchestration of generated transcriptions I find implausible, but musically interesting (see video here: https://youtu.be/RaO4HpM07hE)
 * [“We Three Layers o’ Hidd’n Units Are”](https://soundcloud.com/sturmen-1/we-three-layers-o-hiddn-units-are) comes from my experiments using the system to “complete” well-known xmas tunes, in this case “We Three Kings”. I seeded the system with the first few bars of this carol, and had it generate the rest. After much curation, I orchestrated the results.
